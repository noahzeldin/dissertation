---
title: The Reception of *The Measures Taken* and *The Mother* in the Political-Aesthetic
  Space of the Weimar Republic
author: "Noah Zeldin"
date: "4/27/2021"
output: 
  github_document:
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "C:/Users/Noah Zeldin/Documents/R stuff/R projects/dissertation")
```

# Introductory Remarks

Below is the annotated set-up for my quantitative analysis of the Weimar-era 
reception of Brecht and Eisler's *The Measures Taken* and *The Mother*, which is 
included in the second chapter of my dissertation. This analysis was conducted 
in R and relies heavily on the [quanteda](https://quanteda.io/) package (for 
general manipulation, word counts, etc.) and
[FactoMineR](http://factominer.free.fr/index.html) package (for correspondence 
analysis). (Also, I have tried to use [tidyverse](https://www.tidyverse.org/) 
syntax as consistently as possible.) The data set will be made available to 
researchers upon request.

The **main goals** of this analysis are:

1. to determine the most-discussed aspects of each work (e.g. musical vs. 
theatrical components, politics)

    - In the dissertation, I compare these results to the works' postwar 
    reception. 

2. to determine if there is a measurable correspondence between aesthetics and
politics 

    - Hence the notion of the "political-aesthetic space."

**NB: Further refinements to the code are forthcoming.** The 
final version will be included in the supplementary materials of the 
dissertation.

In the near future, I will upload the corresponding write-up included in ch. 2 
of my dissertation to this repository.

# Load Packages

```{r}
library(tidyverse)
library(readxl)
library(ggplot2)
library(quanteda)
library(FactoMineR)
library(lubridate)
```

# Importation

NB: Several articles had to be removed because of their distortionary effects.
This resulted in three versions of the data, as shown below. 

Main data set containing all articles (`data_main`): 

```{r}
data_main <- read_excel("reception_analysis_data.xlsx", sheet = "all_docs")
```

`data_main` w/o articles on the Erfurt performance *The Measures Taken* 
(`data_no_erfurt`):

```{r}
data_no_erfurt <- data_main %>% 
    filter(Date != "24.01.1933") %>% 
    filter(Date != "25.01.1933") %>% 
    filter(Date != "26.01.1933") %>% 
    filter(Date != "27.01.1933") %>% 
    filter(Newspaper != "Internationaler_Revolutionärer_Theater-Bund_(Bulletin)")
```

* `r nrow(data_main) - nrow(data_no_erfurt)` articles removed from original data 
set 

(`data_main`).

`data_main` without *Measures Taken* articles on Erfurt performance 
or Ferdinand Junghans, "Das Kartenhaus stürzt!," *Neue Preussische 
Kreuz-Zeitung*, n.d. (`data_reduced`):


```{r}
data_reduced <- data_no_erfurt %>% 
    filter(Author != "Ferdinand Junghans")
```

* `r nrow(data_main) - nrow(data_reduced)` articles removed from original data set 
(`data_main`).


# Quanteda Set-Up

## Create Corpora from Data Sets

In addition to the main corpora, I create additional corpora, e.g. based on 
piece, to provide greater flexibility for later analysis, for instance, finding 
and/or counting instances of a keyword in articles on *The Mother*. 

### General Corpora

General Corpus from `data_main` (`corp`):

```{r}
corp <- corpus(data_main, text_field = "Text")
```

Corpus from `data_no_erfurt` (`corp_no_erfurt`):

```{r}
corp_no_erfurt <- corpus(data_no_erfurt, text_field = "Text")
```

Corpus from `data_reduced` (`corp_reduced` ):

```{r}
corp_reduced <- corpus(data_reduced, text_field = "Text")
```

### Corpora Grouped by Piece

*Measures Taken* Corpus (`mt_corp`):

```{r}
mt_corp <- corpus_subset(corp, Piece == "Massnahme")
```

*Measures Taken* Corpus without articles on Erfurt performance 
(`mt_corp_no_erfurt`):

```{r}
mt_corp_no_erfurt <- corpus_subset(corp_no_erfurt, Piece == "Massnahme")
```

* Again, the articles on the Erfurt performance were removed because of their 
distortionary effect.

*Mother* Corpus (`mother_corp`):

```{r}
mother_corp <- corpus_subset(corp, Piece == "Mutter")
```

### Corpora of Title Texts

This allows for later analysis of the texts of the article titles, e.g. keyword 
frequencies.

Title Corpus (all articles) (`corp_title`):

```{r}
corp_title <- corpus(data_main, text_field = "Title")
```

*Mother* Title Corpus (`mother_corp_title`):

```{r}
mother_corp_title <- corpus_subset(corp_title, Piece == "Mutter")
```

## Corpus Summary - Article Lengths, etc.

```{r}
corp_reduced_summary <- textstat_summary(corp_reduced) %>% 
  as_tibble

corp_reduced_summary$document <- corp_reduced_summary$document %>% 
        str_replace("text", "") 
    
corp_reduced_summary <- corp_reduced_summary %>% 
  mutate(document = as.numeric(document)) %>% 
  rename(Article = document) %>% 
  left_join(data_main, by = "Article") %>% 
  select(-c(Text, Other_Metadata:Comp_Doc))
```


## Dictionaries and Additional Stopwords

General Dictionary

* This dictionary contains what I perceived to be the most important keywords in 
the corpus and those on which I wished to focus in my analysis. As I explain in 
ch. 2, I read through all of the articles in the corpus prior to conducting this 
analysis. As a result, I had a clear idea of those terms on which I would focus. 

```{r}
dict_gen <- dictionary(list(revolution = "revolution*",
                            bertolt = c("bert*", "bertolt*"),
                            theater = c("theater*", "theatralisch*"),
                            episch = "episch*",
                            musik = "musik*",
                            drama = "drama*",
                            politisch = "politi*",
                            kommunismus = "kommunis*",
                            chor = c("chor*", "chöre*"), 
                            proletarisch = "prolet*",
                            marxismus = "marx*",
                            primitiv = "primitiv*",
                            lehrstück = "lehrstück*",
                            brecht = "brecht*",
                            eisler = "eisler*",
                            gorki = "gorki*",
                            bürgerlich = "bürgerlich*",
                            propaganda = "propagand*",
                            kunst = c("kunst", "künstler*"),
                            lied = c("lied*", "song*"),
                            arbeitersänger = "arbeitersänger*", 
                            arbeiterchor = "arbeiterch*", 
                            bolschewismus = c("bolschewis*",
                                              "kulturbolschewis*"), 
                            langweilig = c("langweilig*", 
                                           "langeweile")))
```

Regular Expressions Dictionary

* In the case of pedagogical terms, it was necessary to use regular expressions. As I explain in ch. 2, **LEHRLERN** is the only keyword defined in these 
dictionaries that can be considered an interpretative combination of different 
words, rather than a mere grouping of synonyms. **LEHRLERN** groups together 
words relating to the following terms (the regular expressions should cover all 
forms of the terms: nouns, verbs, adjectives and adverbs).

  * "teaching" [*lehren*] 

  * "learning" [*lernen* (and past particple, *gelernt*) and *erlernen*]

  * "instructing" [*belehren*]

  * "pedagogical" [*pädagogisch*]

  * "didactic" [*didaktisch*]

```{r}
dict_regex <- dictionary(list(lehrlern = c("lehr(?!s)[a-z]+", 
                                           "belehr(?!s)[a-z]+", 
                                           "lern[a-z]+",
                                           "erlern[a-z]+", 
                                           "gelern[a-z]+", 
                                           "pädagog[a-z]+", 
                                           "didakt[a-z]+"))) 
```

Additional Stopwords

* These stopwords are not part of the set of German stopwords provided in 
**quanteda**.

```{r}
sw_add <- c("dass", "wurde", "schon", "mehr", "ganz*", "immer", "gibt", "ja",
            "müssen", "kommt", "sei", "tun")
```

## Tokenize and Filter Corpora

Create function for tokenizing and removing stopwords, punctuation and other 
symbols:

```{r}
tokenize_and_remove_stopwords <- function(i) {
    tokens(i,
           remove_punct = TRUE,
           remove_numbers = TRUE,
           remove_symbols = TRUE) %>% 
        tokens_remove(c(stopwords("de"), sw_add)) %>% 
        tokens_remove(valuetype = "regex", "[0-9]+") %>% 
        tokens_keep(min_nchar = 3) 
}
```

Tokenize and filter corpora (results in tokens object, labeled `_toks`):

```{r}
# general / ungrouped
gen_toks <- tokenize_and_remove_stopwords(corp)

# general / ungrouped NO ERFURT
gen_toks_no_erfurt <- tokenize_and_remove_stopwords(corp_no_erfurt)

# general / ungrouped REDUCED
gen_toks_reduced <- tokenize_and_remove_stopwords(corp_reduced)

# Measures Taken
mt_toks <- tokenize_and_remove_stopwords(mt_corp)

# Measures Taken NO ERFURT
mt_toks_no_erfurt <- tokenize_and_remove_stopwords(mt_corp_no_erfurt)

# Mother
mother_toks <- tokenize_and_remove_stopwords(mother_corp)

# Mother TITLE
mother_title_toks <- tokenize_and_remove_stopwords(mother_corp_title)
```

## Document-Feature Matrices (dfm)

Create function for converting tokenized items from previous section (ending in 
`_toks`) to dfm and applying dictionaries:

```{r}
convert_to_dfm_and_apply_dictionaries <- function(i) {
    dfm(i) %>% 
        dfm_lookup(dict_gen, exclusive = FALSE) %>% 
        dfm_lookup(dict_regex, valuetype = "regex", exclusive = FALSE)
}
```

Convert and apply dictionaries to tokens objects, using above-defined function:

```{r}
# general / ungrouped
gen_dfm <- convert_to_dfm_and_apply_dictionaries(gen_toks)
# general / ungrouped NO ERFURT
gen_dfm_no_erfurt <- convert_to_dfm_and_apply_dictionaries(gen_toks_no_erfurt)
# general / ungrouped REDUCD
gen_dfm_reduced <- convert_to_dfm_and_apply_dictionaries(gen_toks_reduced)
# Measures Taken 
mt_dfm <- convert_to_dfm_and_apply_dictionaries(mt_toks)
# Measures Taken NO ERFURT
mt_dfm_no_erfurt <- convert_to_dfm_and_apply_dictionaries(mt_toks_no_erfurt)
# Mother
mother_dfm <- convert_to_dfm_and_apply_dictionaries(mother_toks)
# ADDITION 12.17.20: Mother TITLE
mother_title_dfm <- convert_to_dfm_and_apply_dictionaries(mother_title_toks)
```

### Group dfm's by General Political Orientation (GPO) 

**GPO** or "general political orientation" is a variable included in the 
original data set and is used extensively in the later analyses. It must be 
added back int dfm's, using the `groups` function in **quanteda**. 

Here, we group the data by both piece and GPO, which results in 8 groups total.

```{r}
grouped_dfm <- dfm_group(gen_dfm,
                         groups = c("Piece",
                                    "Generalized_Political_Orientation"))

# same but NO ERFURT
grouped_dfm_no_erfurt <- dfm_group(gen_dfm_no_erfurt,
                                   groups = c("Piece",
                                             "Generalized_Political_Orientation"))
```


### Create GPO grouped dfm's for each piece 

NB: Only the third of these (`mother_dfm_gpo`) is used in the analysis but all
three have been kept for consistency.

```{r}
# Measures Taken
mt_dfm_gpo <- dfm_group(mt_dfm,
                          groups = "Generalized_Political_Orientation")

# Measures Taken NO ERFURT
mt_dfm_gpo_no_erfurt <- dfm_group(mt_dfm_no_erfurt,
                                    groups = "Generalized_Political_Orientation")

# Mother
mother_dfm_gpo <- dfm_group(mother_dfm,
                            groups = "Generalized_Political_Orientation")
```

### Less Specific Groupings

NB: The first two, which contain articles related to the Erfurt performance of 
*The Measures Taken*, have been created for the sake of consistency but are not 
used in the later analyses.

```{r}
# by piece
piece_dfm <- dfm_group(gen_dfm,
                       groups = "Piece")

# by GPO
gpo_dfm <- dfm_group(gen_dfm,
                     groups = "Generalized_Political_Orientation")


# less specific groupings NO ERFURT

# by piece
piece_dfm_no_erfurt <- dfm_group(gen_dfm_no_erfurt,
                                 groups = "Piece")

# by GPO
gpo_dfm_no_erfurt <- dfm_group(gen_dfm_no_erfurt,
                               groups = "Generalized_Political_Orientation")
```

### By GPO

Not currently used in the analysis but leaving for the moment.

```{r}
# Left
left_sub <- dfm_subset(grouped_dfm, 
                       Generalized_Political_Orientation == "Left")

# Right
right_sub <- dfm_subset(grouped_dfm, 
                        Generalized_Political_Orientation == "Right")

# Center
center_sub <- dfm_subset(grouped_dfm, 
                         Generalized_Political_Orientation == "Center")

# Unknown
unknown_sub <- dfm_subset(grouped_dfm,
                          Generalized_Political_Orientation == "Unknown")
```

### By Piece

Not currently used in the analysis but leaving for the moment.

```{r}
# Measures Taken
mt_sub <- dfm_subset(grouped_dfm,
                            Piece == "Massnahme")

# Mother
mother_sub <- dfm_subset(grouped_dfm,
                         Piece == "Mutter")
```

## Convert general (reduced) corpus and dfm to dataframes for later use

```{r}
# convert gen_dfm_reduced to dataframe
gen_datafr_reduced <- convert(gen_dfm_reduced, to = "data.frame")

# convert corp_reduced to dataframe (contains GPOs + other metadata)
corp_reduced_datafr <- convert(corp_reduced, to = "data.frame")
```


## Create corpus, dfm, ca, etc. of each piece w/o unknown GPO (for CA)

This is necessary for the CA, where I exclude those articles for which the GPO 
is unknown.

Create dfm without distortionary Erfurt articles or articles with unknown GPO:

```{r}
# broken up into 3 separate steps for legibility

corp_no_erfurt_or_unknown <- 
  corpus_subset(corp_no_erfurt, 
                ! Generalized_Political_Orientation == "Unknown" )

toks_no_erfurt_or_unknown <- 
  tokenize_and_remove_stopwords(corp_no_erfurt_or_unknown)

dfm_no_erfurt_or_unknown <- 
  convert_to_dfm_and_apply_dictionaries(toks_no_erfurt_or_unknown)
```

Just GPO, not piece (not currently using):

```{r}
gpo_dfm_no_erfurt_or_unknown <- dfm_group(dfm_no_erfurt_or_unknown,
                                          groups = "Generalized_Political_Orientation")
```

Grouped by piece and GPO:

```{r}
grouped_dfm_no_erfurt_or_unknown <- 
  dfm_group(dfm_no_erfurt_or_unknown, 
            groups = c("Piece", "Generalized_Political_Orientation"))
```

Only articles on *The Measures Taken*:

```{r}
mt_corp_no_erfurt_or_unknown <- 
  corpus_subset(corp_no_erfurt,
                Piece == "Massnahme" &! 
                  Generalized_Political_Orientation == "Unknown" )


mt_toks_no_erfurt_or_unknown <- 
  tokenize_and_remove_stopwords(mt_corp_no_erfurt_or_unknown)

mt_dfm_no_erfurt_or_unknown <- 
  convert_to_dfm_and_apply_dictionaries(mt_toks_no_erfurt_or_unknown)

mt_dfm_gpo_no_erfurt_or_unknown <- 
  dfm_group(mt_dfm_no_erfurt_or_unknown, 
            groups = "Generalized_Political_Orientation")
```

Only articles on *The Mother*:

```{r}
mother_corp_no_unknown <- 
  corpus_subset(corp, 
                Piece == "Mutter" &! 
                  Generalized_Political_Orientation == "Unknown" )

mother_toks_no_unknown <- tokenize_and_remove_stopwords(mother_corp_no_unknown)

mother_dfm_no_unknown <- 
  convert_to_dfm_and_apply_dictionaries(mother_toks_no_unknown)

mother_dfm_gpo_no_unknown <- 
  dfm_group(mother_dfm_no_unknown, 
            groups = "Generalized_Political_Orientation")
```


# FactoMineR Set-Up (for CA)

Create function for converting dfm to dataframe and performing CA:

```{r}
convert_to_dataframe_and_perform_ca <- function(i) {
    convert(i, to = "data.frame") %>% 
        CA(quali.sup = 1, graph = FALSE)
}
```

* NB: I originally created this function, because I performed the CA on 
multiple versions of the data set. I may delete it in the future and integrate 
the necessary code in the step below.

Create dfm with proper group names (will appear in CA graph) and apply 
above-defined function:

```{r}
grouped_dfm_no_erfurt_or_unknown <- 
  dfm_group(grouped_dfm_no_erfurt_or_unknown,
            groups = c("Measures.Center", "Mother.Center", "Measures.Left",
                       "Mother.Left", "Measures.Right", "Mother.Right"))

grouped_ca_no_erfurt_or_unknown <- 
  convert_to_dataframe_and_perform_ca(grouped_dfm_no_erfurt_or_unknown)
```



# Keywords In Context (KWIC) and Keyword Exploration

## Create function to link KWIC with data

```{r}
combine_kwic_with_data <- function(corpus, words, window) {
    
    i <- kwic(corpus, words, window = window) %>% 
        as_tibble() 
    
    i$docname <- i$docname %>% 
        str_replace("text", "") 
    
    i <- i %>% mutate(docname = as.numeric(docname)) %>% 
        rename(Article = docname) %>% 
        left_join(
          data_reduced, 
          by = "Article") %>% 
        select(-c(Text, Other_Metadata:Comp_Doc))
    
    }
```

## Explore various KWIC 

All of these keywords relate to claims made in ch. 2 of the dissertation. (All 
words are written lowercase to reflect how they appear post-processing.)

* primitiv [primitive]

```{r}
primitiv_kwic <- 
  combine_kwic_with_data(corp, "primitiv*", 15)
```

* langweilig [boring]

```{r}
langweilig_kwic <- 
  combine_kwic_with_data(corp, c("langeweile", "langweilig*"), 10)
```

* langweilig + primitiv

```{r}
langweilig_primitiv_kwic <- 
  inner_join(langweilig_kwic, primitiv_kwic, by = "Article")
```

* proletarisch [proletarian]

```{r}
proletarisch_kwic <- 
  combine_kwic_with_data(corp, "proletarisch*", 10)
```

* pudowkin [[Pudovkin](https://en.wikipedia.org/wiki/Vsevolod_Pudovkin)]

```{r}
pudowkin_kwic <- 
  combine_kwic_with_data(corp, "pudowkin*", 10)
```

* kunst [art]

```{r}
kunst_kwic <- 
  combine_kwic_with_data(corp, c("kunst", "künstler*"), 10)
```

* agitprop

```{r}
agitprop_kwic <- 
  combine_kwic_with_data(corp, "agitprop*", 10)
```

* bildung

```{r}
bildung_kwic <- 
  combine_kwic_with_data(corp, "bildung", 10)
```

* wissen [knowledge]

```{r}
wissen_kwic <- 
  combine_kwic_with_data(corp, "wissen*", 10)
```

* lehrstück [learning-piece] - *The Mother*

```{r}
lehrstueck_mother_kwic <- 
  combine_kwic_with_data(corp, "lehrstück*", 10) %>% 
  filter(Piece == "Mutter")
```

* oratorium [oratorio] - *The Measures Taken*

```{r}
oratorium_mt_kwic <- 
  combine_kwic_with_data(corp, "oratori*", 30) %>% 
  filter(Piece == "Massnahme")
```

* arbeitersänger [worker-singer(s)] - *The Measures Taken*

```{r}
arbeitersaenger_mt_kwic <- 
  combine_kwic_with_data(corp, "arbeitersänger*", 30) %>% 
  filter(Piece == "Massnahme")
```

* stalin and stalinismus [Stalinism]

```{r}
combine_kwic_with_data(corp, "stalin*", 30) %>% 
  print()
```

Only 3 articles on Mother.

* cantata

```{r}
combine_kwic_with_data(corp, "Kantate*", 25) %>% 
  print()
```

No results.

### Special Case: LEHRLERN in rightwing articles on The Mother

As I explain in ch. 2, **LEHRLERN** is the only term in the keyword diction (see
above) that can be considered an interpretative combination of different words, 
rather than a mere grouping of synonyms. **LEHRLERN** groups together words 
relating to "teaching" [*lehren*], "learning" [*lernen*] and "pedagogy."

Create tibble:

```{r}
lehrlern_kwic <- kwic(corp, dict_regex, window = 20, valuetype = "regex") %>% 
  as_tibble()

lehrlern_kwic$docname <- lehrlern_kwic$docname %>% 
    str_replace("text", "") 

lehrlern_kwic <- lehrlern_kwic %>% 
  mutate(docname = as.numeric(docname)) %>% 
  rename(Article = docname) %>% 
  left_join(data_main, by = "Article") %>% 
  select(-c(Text, Other_Metadata:Comp_Doc))
```

Filter for *The Mother* and right GPO:

```{r}
lehrlern_kwic_mother_right <- lehrlern_kwic %>% 
  filter(Piece == "Mutter" & Generalized_Political_Orientation == "Right")
```

## Additional Terms Post-Processing (DFMs)

LEHRLERN in Mother

```{r}
lehrlern_mother_gpo_count <-  
  dfm_select(mother_dfm_gpo, pattern = "LEHRLERN") %>% 
  as_tibble()

lehrlern_mother_gpo_count
```


# Dates of Publication with Counts

## Create Tables

### General

All articles:

```{r}
dates_tib <- corp_reduced_datafr %>% 
  as_tibble() %>% 
  select(Article, Date, Piece) %>% 
  group_by(Piece, Date) %>% 
  count(Date) %>% 
  arrange(desc(n))
```

Separate columns:

```{r}
dates_tib_separate <- corp_reduced_datafr %>% 
  as_tibble() %>% 
    select(Article, Date, Piece) %>% 
    filter(str_detect(Date, "\\S{2}\\.\\S{2}\\.[:digit:]{4}")) %>% 
    separate(Date, sep = "\\.", into = c("day", "month", "year"))
```

Make compatible with [Lubridate](https://lubridate.tidyverse.org/) package:

```{r}
dates_tib_lubridate <- dates_tib_separate %>% 
    mutate(day = as.numeric(day), 
           month = as.numeric(month),
           year = as.numeric(year)) %>%
    relocate(day, .after = month) %>% 
    relocate(year, .before = month) %>% 
    mutate(date = make_date(year, month, day)) %>% 
    select(Article, date, Piece) %>% 
  filter(!is.na(date)) %>% 
  arrange(date)
```

Percent of articles *without* full dates (i.e. excluded from Lubridate):

```{r}
articles_perc_without_full_dates <- 
  (((nrow(dates_tib_separate) - 
     nrow(dates_tib_lubridate)) 
  / nrow(dates_tib_lubridate)) * 100) %>% 
  round() 
```

`r articles_perc_without_full_dates`% of articles do *not* have full dates.

Percent of articles *with* full dates (i.e. included for Lubridate):

```{r}
articles_perc_with_full_dates <- 100 - articles_perc_without_full_dates
```

`r articles_perc_with_full_dates`% of articles have full dates.

### By Piece

#### Measures Taken

<!-- may not need this first one (non-Lubridate) -->

All

```{r}
dates_mt <- dates_tib %>% 
  filter(Piece == "Massnahme") %>% 
  ungroup %>% 
  select(-Piece)
```

Edited, for Lubridate

* Chronological, w/o counts (saved for computing range, length, etc. for 
write-up):

```{r}
dates_mt_lubridate <- 
  dates_tib_lubridate %>% 
  filter(Piece == "Massnahme") %>% 
  arrange(date)
```


* Counted and sorted descending:

```{r}
dates_tib_lubridate %>% 
  filter(Piece == "Massnahme") %>%
  count(date) %>% 
  arrange(desc(n))
```


#### Mother

All

```{r}
dates_mother <- dates_tib %>% 
  filter(Piece == "Mutter") %>% 
  ungroup %>% 
  select(-Piece)
```

Edited, for Lubridate

* Chronological, w/o counts (saved for computing range, length, etc. for 
write-up):

```{r}
dates_mother_lubridate <- 
  dates_tib_lubridate %>% 
  filter(Piece == "Mutter") %>% 
  arrange(date)
```

* Counted and sorted descending:

```{r}
dates_tib_lubridate %>% 
  filter(Piece == "Mutter") %>%
  count(date) %>% 
  arrange(desc(n))
```

## Date Ranges, Time Lengths, etc.

### Time Length in Years

All Articles (edited for Lubridate):

```{r}
difftime(tail(dates_tib_lubridate$date, 1),
         head(dates_tib_lubridate$date, 1)) %>% 
  time_length(unit = "year")
```

*The Measures Taken*

```{r}
difftime(tail(dates_mt_lubridate$date, 1),
         head(dates_mt_lubridate$date, 1)) %>% 
  time_length(unit = "year")
```

*The Mother*

```{r}
difftime(tail(dates_mother_lubridate$date, 1),
         head(dates_mother_lubridate$date, 1)) %>% 
  time_length(unit = "year")
```

### Range / Interval 

#### All

Save general start and end dates as variables for write-up:

```{r}
articles_first_date <- head(dates_tib_lubridate$date, 1)

articles_last_date <- tail(dates_tib_lubridate$date, 1)
```


General dates interval:

```{r}
interval(start = articles_first_date,
         end = articles_last_date)
```

#### The Measures Taken

```{r}
interval(start = head(dates_mt_lubridate$date, 1),
         end = tail(dates_mt_lubridate$date, 1))
```

#### The Mother

```{r}
interval(start = head(dates_mother_lubridate$date, 1),
         end = tail(dates_mother_lubridate$date, 1))
```

### Proportion of Articles Published near Premieres

#### The Measures Taken

Save date of premiere as variable (cf.
[GBA](https://www.suhrkamp.de/werkausgabe/werke_grosse_kommentierte_berliner_und_frankfurter_ausgabe_30_baende_in_32_teilbaenden_und_ein_registerband_leinen_24.html) 
3: 431):

```{r}
mt_premiere_date <- ymd("1930-12-13")
```

Create interval for 1 week after premiere:

```{r}
mt_premiere_week <- interval(start = mt_premiere_date,
         end = mt_premiere_date + dweeks(x = 1))
```

Percentage of articles published within 1 week of premiere:

```{r}
articles_mt_premiere_week_perc <- 
  round(((dates_mt_lubridate %>% 
    filter(date %within% mt_premiere_week) %>% 
    nrow()) / nrow(dates_mt_lubridate)) * 100)
```

`r articles_mt_premiere_week_perc`% of articles on *The Measures Taken* were 
published within one week of the premiere.

#### The Mother

Save date of premiere (cf.
[GBA](https://www.suhrkamp.de/werkausgabe/werke_grosse_kommentierte_berliner_und_frankfurter_ausgabe_30_baende_in_32_teilbaenden_und_ein_registerband_leinen_24.html) 
3: 478):

```{r}
mother_premiere_date <- ymd("1932-01-17")
```

Create interval for 1 week after premiere:

```{r}
mother_premiere_week <- interval(start = mother_premiere_date,
         end = mother_premiere_date + dweeks(x = 1))
```

Percentage of articles published within 1 week of premiere:

```{r}
articles_mother_premiere_week_perc <- 
  round(((dates_mother_lubridate %>% 
    filter(date %within% mother_premiere_week) %>% 
    nrow()) / nrow(dates_mother_lubridate)) * 100)
```

`r articles_mother_premiere_week_perc`% of articles on *The Mother* were 
published within one week of the premiere.

## Articles on The Measures Taken published in 1932

```{r}
dates_tib_lubridate %>% 
    filter(Piece == "Massnahme" &
            year(date) == 1932) %>% 
    left_join(data_main)
```


# Visualizations

Create color scheme:

```{r}
colors_four <- c("#E41A1C", "#377EB8", "#4DAF4A", "#984EA3")
```


Create English labels for both works:

```{r}
labels_english <- c(Massnahme = "Measures Taken", Mutter = "Mother")
```

## Visual Summary of Reduced Corpus

Set-up for boxplot:

```{r}
# 3 steps for set-up

# STEP 1
# create table with total number of tokens for each article
toks_grouped <- gen_datafr_reduced %>% 
    mutate(toks_sum = rowSums(.[ ,2:ncol(.)]), .after = 1) %>% 
    select(doc_id, toks_sum)

# NB: possible to use tidyverse syntax but much slower (including for reference)
# gen_datafr_reduced %>%
    # rowwise() %>% mutate(toks_sum = sum(c_across(2:ncol(.))), .after = 1)

# STEP 2
# add GPO column to gen_datafr_reduced (can't combine with above)
toks_grouped <- 
  left_join(toks_grouped, 
            corp_reduced_datafr[ , c("doc_id", 
                                     "Generalized_Political_Orientation", 
                                     "Piece")], 
            by = "doc_id", 
            copy = TRUE)

# STEP 3
# added for observation counts
toks_grouped <- toks_grouped %>% 
    add_count(Piece, Generalized_Political_Orientation)

# STEP 4
# must save GPO as factor and relevel, so that Left appears first
toks_grouped <- toks_grouped %>% 
    mutate(Generalized_Political_Orientation = 
               as.factor(Generalized_Political_Orientation))

toks_grouped$Generalized_Political_Orientation <- 
    toks_grouped$Generalized_Political_Orientation %>% fct_relevel("Left")
```

Code for boxplot:

```{r, fig.width = 9, fig.height=7}
toks_summary_boxplot <- toks_grouped %>% 
    ggplot(aes(x = Piece, y = toks_sum, 
               fill = Generalized_Political_Orientation)) +
    geom_boxplot(alpha = 0.7,
                 varwidth = FALSE) +
    stat_summary(fun = median, geom = "point", 
                 shape = 21, size = 4, color = "black", fill = "yellow2", 
                 alpha = 0.6) +
    stat_summary(fun = median, geom = "line", 
                 size = 1.2, color = "yellow2", alpha = 0.5, aes(group = 1)) +
    scale_fill_brewer(type = "seq", palette = "Set1") +
    geom_jitter(color = "darkgrey",
                size = 1.25, alpha = 0.95,
                show.legend = FALSE) + 
    coord_cartesian(xlim = NULL, ylim = c(0, 900)) +
    ylab("Tokens") + 
    scale_x_discrete(labels = c("Measures Taken", "Mother")) +
    xlab(NULL) +
    labs(fill = "Political Orientation",
         title = "Tokens per Article (Post-Processing)",
         subtitle = "Scaled for readability. Several outliers excluded.", 
         caption = "Yellow points denote the median tokens per article for each piece. NB: The positions of the scatter points do not correspond to political orientation.") +
    geom_text(aes(label = ..count.., 
                  y = ..prop..), 
              stat = "count",
              position = position_dodge(0.75)) +
    theme(axis.title.x = element_blank(),
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_line(color = "grey", linetype = 3),
          panel.grid.minor.y = element_line(color = "grey", linetype = 3),
          plot.caption.position = "plot",
          panel.background = element_rect(fill = "white", colour = 'black'))

toks_summary_boxplot
```

A couple of quick points, which I review in the write-up in greater detail:

* There are far more articles on *The Mother* than on *The Measures Taken*.

* Articles on *The Measures Taken* tend to be longer than those on *The Mother*.

* Articles on *The Measures Taken* are overwhelmingly from leftwing 
publications.


### Very Long Articles

The goal is to identify the very long articles in *Measures - Unknown* category, 
because they stretch out the IQR.

```{r}
corp_reduced_summary %>% 
    filter(Generalized_Political_Orientation == "Unknown" &
               Piece == "Massnahme") %>% 
    arrange(desc(tokens)) %>% 
  select(Article, tokens, Title:Piece)
```

## Wordclouds

Grouped by Piece:

```{r, fig.width=9, fig.height=9}
# must rename groups in English for word cloud
piece_dfm_no_erfurt_english <- dfm_group(piece_dfm_no_erfurt, 
                                         groups = c("Measures Taken", "Mother"))

textplot_wordcloud(piece_dfm_no_erfurt_english,
                   max_words = 100,
                   color = colors_four,
                   rotation = FALSE,
                   comparison = TRUE,
                   labelcolor = "black")
```

*Mother* - Grouped by GPO (no unknown):

```{r, results='hide', fig.width=9, fig.height=9}
wordcloud_mother_gpo <- 
  textplot_wordcloud(mother_dfm_gpo_no_unknown,
                   max_words = 100,
                   rotation = FALSE,
                   # must do manual order for colors, so that Left is red
                   color = c("#377EB8", "#E41A1C", "#4DAF4A", "#984EA3"),
                   comparison = TRUE,
                   labelcolor = "black")
```


## Word Frequency 

By Piece:

```{r, fig.width=9, fig.height=8}
# grouped by piece (weighted)
freq_piece <- dfm_weight(gen_dfm_reduced, scheme = "prop") %>% 
    textstat_frequency(n = 15, groups = "Piece")

freq_piece_plot <- 
  ggplot(freq_piece, 
       aes(x = nrow(freq_piece):1, y = frequency, fill = group)) +
    geom_col() +
    facet_wrap(~ group, scales = "free", nrow = 2,
               labeller = labeller(group = labels_english)
               ) +
    coord_flip() +
    scale_x_continuous(breaks = nrow(freq_piece):1, 
                       labels = freq_piece$feature) +
    labs(x = NULL, y = "Relative Frequency") +
    scale_fill_manual(values = colors_four) + # prob could just use brewer, b/c only 2
    theme_bw() +
    theme(legend.position = "none",
          panel.grid.major.y = element_line(color = "grey", linetype = 3),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.x = element_line(color = "grey", linetype = 3),
          panel.grid.minor.x = element_line(color = "grey", linetype = 3),
          plot.caption.position = "plot",
          panel.background = element_rect(fill = "white", colour = 'black'))

freq_piece_plot
```

By Piece + GPO:

```{r, fig.width=11, fig.height=8}
# create weighted frequency table
freq_grouped_wt <- dfm_weight(gen_dfm_reduced, scheme = "prop") %>% 
    textstat_frequency(n = 10, 
                       groups = c("Piece", "Generalized_Political_Orientation")) 

# rename groups
freq_grouped_wt <- freq_grouped_wt %>% 
    mutate(group = str_replace_all(group, 
                                   c("Massnahme.Left" = "Measures Taken | Left", 
                                     "Massnahme.Center" = 
                                       "Measures Taken | Center", 
                                     "Massnahme.Right" = 
                                       "Measures Taken | Right",
                                     "Massnahme.Unknown" = 
                                       "Measures Taken | Unknown",
                                     "Mutter.Left" = "Mother | Left",
                                     "Mutter.Center" = "Mother | Center",
                                     "Mutter.Right" = "Mother | Right",
                                     "Mutter.Unknown" = "Mother | Unknown")))

# save group column as factor and reorder
freq_grouped_wt$group <- freq_grouped_wt$group %>% as.factor() 

freq_grouped_wt$group <- freq_grouped_wt$group %>% 
    fct_relevel("Measures Taken | Left") %>% 
    fct_relevel("Mother | Left", after = 4)

# code for graph
freq_piece_gpo_plot <- ggplot(freq_grouped_wt, 
       aes(x = nrow(freq_grouped_wt):1, y = frequency, fill = group)) +
    geom_col() +
    facet_wrap(~ group, scales = "free", nrow = 2) +
    coord_flip() +
    scale_x_continuous(breaks = nrow(freq_grouped_wt):1, 
                       labels = freq_grouped_wt$feature) +
    labs(x = NULL, y = "Relative Frequency") +
    scale_fill_manual(values = c(colors_four, colors_four)) + # repeat b/c need 8
    theme_bw() +
    theme(legend.position = "none",
          panel.grid.major.y = element_line(color = "grey", linetype = 3),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.x = element_line(color = "grey", linetype = 3),
          panel.grid.minor.x = element_line(color = "grey", linetype = 3),
          plot.caption.position = "plot",
          panel.background = element_rect(fill = "white", colour = 'black'))

freq_piece_gpo_plot
```

## Correspondence Analysis


Main

```{r, fig.width=11, fig.height=11}
ca_main <- plot(grouped_ca_no_erfurt_or_unknown,
                invisible = "row",
                col.quali.sup = "darkblue",
                selectCol = "contrib 20",
                autoLab = "y", 
                ylim = c(-0.75, 1.75), 
                unselect = 1,
                cex = 0.85)

ca_main <- ca_main + 
    labs(title = "The Political-Aesthetic Space of The Measures Taken and The Mother",
         subtitle = "(CA of pieces and political orientations with the top 20 contributing keywords.)") +
    theme_bw()

ca_main
```

*Measures Taken*

```{r, fig.width=10, fig.height=10}
ca_measures <- plot(grouped_ca_no_erfurt_or_unknown,
     invisible = "row",
     col.quali.sup = "darkblue",
     selectCol = "contrib 20",
     autoLab = "y",
     xlim = c(0, 1.5),
     ylim = c(-1, 2), 
     unselect = 1,
     cex = 0.85)

ca_measures <- ca_measures + 
  labs(title = "The Political-Aesthetic Space of The Measures Taken",
       subtitle = "(Enlargement of positive x region of above.)") +
  theme_bw()

ca_measures
```

*Mother*

```{r, fig.width=10, fig.height=10}
ca_mother <- plot(grouped_ca_no_erfurt_or_unknown,
     invisible = "row",
     col.quali.sup = "darkblue",
     selectCol = "contrib 20",
     autoLab = "y",
     xlim = c(-1.25, 0),
     ylim = c(-0.75, 0.25), 
     unselect = 1,
     cex = 0.85)

ca_mother <- ca_mother + 
  labs(title = "The Political-Aesthetic Space of The Mother",
       subtitle = "(Enlargement of negative x region of above.)") +
  theme_bw() 

ca_mother
```



